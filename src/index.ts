import 'dotenv/config';
import logger from './infrastructure/logging/Logger';
import { container, AppConfig } from './infrastructure/di/index';
import { UncaughtErrorMiddleware } from './infrastructure/middleware/UncaughtErrorMiddleware';
import { DependencyContainer } from './infrastructure/di';
import path from 'path';
import fs from 'fs';
import { exec } from 'child_process';

// Inicializar manejo de errores no capturados
const uncaughtErrorMiddleware = new UncaughtErrorMiddleware(logger);
uncaughtErrorMiddleware.initialize();

// Verificar si el modelo Llama est√° disponible
const checkModelAvailability = () => {
  const modelPath = process.env.LLAMA_MODEL_PATH || path.join(process.cwd(), 'models', 'llama-model.gguf');
  
  if (!fs.existsSync(modelPath)) {
    logger.warn('‚ö†Ô∏è No se ha encontrado un modelo Llama en la ruta configurada:', modelPath);
    logger.info('‚ÑπÔ∏è Puedes descargar autom√°ticamente un modelo ejecutando: npm run download:llama');
    
    // Preguntar al usuario si desea descargar el modelo autom√°ticamente
    if (process.stdout.isTTY) { // Solo en entorno interactivo (no en producci√≥n)
      console.log('\n\nü§ñ ¬øDeseas descargar autom√°ticamente el modelo Llama ahora? (S/n):');
      
      // Configurar entrada est√°ndar para la respuesta
      process.stdin.resume();
      process.stdin.setEncoding('utf8');
      
      process.stdin.once('data', (data) => {
        const response = data.toString().trim().toLowerCase();
        
        if (response !== 'n') {
          console.log('\nüì• Iniciando descarga del modelo...\n');
          
          // Ejecutar script de descarga
          const downloadProcess = exec('npm run download:llama');
          
          // Redirigir salida del proceso a la consola principal
          downloadProcess.stdout?.pipe(process.stdout);
          downloadProcess.stderr?.pipe(process.stderr);
          
          downloadProcess.on('exit', (code) => {
            if (code === 0) {
              console.log('\n‚úÖ Modelo descargado correctamente. Reiniciando aplicaci√≥n...');
              startApplication();
            } else {
              console.error('\n‚ùå Error al descargar el modelo. Por favor, int√©ntelo manualmente: npm run download:llama');
              startApplication();
            }
          });
        } else {
          console.log('\n‚è≠Ô∏è Continuando sin descargar el modelo...');
          startApplication();
        }
      });
      
      return false; // No iniciar la aplicaci√≥n todav√≠a
    }
  }
  
  return true; // El modelo existe o no estamos en un entorno interactivo
};

// Funci√≥n para iniciar la aplicaci√≥n
const startApplication = async () => {
  try {
    logger.info('üöÄ Iniciando TG-TheGuardian...');
    
    // Inicializar el contenedor de dependencias
    const container = DependencyContainer.getInstance();
    
    // Configuraci√≥n y conexi√≥n a servicios externos
    await container.initialize({
      mongoUri: process.env.MONGODB_URI,
      redisConfig: {
        host: process.env.REDIS_HOST || 'localhost',
        port: parseInt(process.env.REDIS_PORT || '6379'),
        password: process.env.REDIS_PASSWORD,
      },
      llamaModelPath: process.env.LLAMA_MODEL_PATH,
      slackPort: parseInt(process.env.PORT || '3001')
    });
    
    // Manejar se√±ales de t√©rmino
process.on('SIGTERM', () => {
      logger.info('üõë Recibida se√±al SIGTERM, cerrando aplicaci√≥n...');
  process.exit(0);
});

process.on('SIGINT', () => {
      logger.info('üõë Recibida se√±al SIGINT, cerrando aplicaci√≥n...');
  process.exit(0);
});

    logger.info('‚úÖ TG-TheGuardian iniciado correctamente');
  } catch (error) {
    logger.error('‚ùå Error al iniciar la aplicaci√≥n:', error);
    process.exit(1);
  }
};

// Iniciar la aplicaci√≥n verificando primero si el modelo est√° disponible
if (checkModelAvailability()) {
  startApplication();
} 